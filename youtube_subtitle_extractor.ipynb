{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN07uHOlES4/4O9laPKasPL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/getcher123/YouTube-Subtitle-Extractor/blob/main/youtube_subtitle_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YouTube Subtitle Extractor\n",
        "\n",
        "This script extracts subtitles of YouTube videos in English and Russian languages, cleans the text and saves them into an Excel file for parallel corpus creation.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "The following packages are required to run the script:\n",
        "- pandas\n",
        "- re\n",
        "- os\n",
        "- itertools\n",
        "# - YouTubeTranscriptApi (Install using `!pip install youtube_transcript_api`)\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Set the `video_ids` and `channelId` variables to the list of video IDs and YouTube channel ID for which you want to extract subtitles.\n",
        "2. Run the script in your preferred Python environment.\n",
        "\n",
        "The script will extract subtitles for the specified video IDs, clean the text, compare English and Russian subtitles to remove any discrepancies, and save the final result in an Excel file in the specified directory.\n",
        "\n",
        "The saved Excel file will have two columns:\n",
        "- `en` - English subtitle\n",
        "- `ru` - Russian subtitle\n",
        "\n",
        "## Notes\n",
        "\n",
        "- If a video doesn't have English or Russian subtitles, it will be skipped.\n",
        "- The script splits subtitles by sentence boundaries and cleans the text by removing unnecessary characters such as `..., “, ’, etc`.\n",
        "- To remove discrepancies between English and Russian subtitles, the script compares the timestamps in the subtitles and deletes the sentence that doesn't have a matching timestamp in the other language. If there are multiple discrepancies, it may leave some of them unpaired."
      ],
      "metadata": {
        "id": "T-olChaWcB-W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juMUUGEKA2Ey"
      },
      "outputs": [],
      "source": [
        "# Mount my Google Drive (storage)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# data dir\n",
        "import os\n",
        "data_dir = '/content/gdrive/MyDrive/subtitles'  # Your data directory in Colab \n",
        "os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install libraries\n",
        "!pip install google-api-python-client\n",
        "!pip install youtube_transcript_api\n",
        "\n",
        "# importing libraries \n",
        "import pandas\n",
        "import json\n",
        "from googleapiclient.discovery import build # Google API request\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "# Enter your YouTube api key\n",
        "api_key = '' \n",
        "# If the address of the Youtube is https://youtu.be/zOjov-2OZ0E then, the video id is tha last part \"zOjov-2OZ0E\"."
      ],
      "metadata": {
        "id": "sqpIl0BIA3kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get subs from one video ID"
      ],
      "metadata": {
        "id": "PsL5NbTDS-sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = 'E21kilDE8jY' \n",
        "\n",
        "subtitles_en = YouTubeTranscriptApi.get_transcript(video_id, languages=['en']) # English subtitle\n",
        "subtitles_ru = YouTubeTranscriptApi.get_transcript(video_id, languages=['ru'])\n",
        "\n",
        "prompts = []\n",
        "words = []\n",
        "for subtitle in subtitles: \n",
        "  time = subtitle['start']\n",
        "  prompt = subtitle['text']\n",
        "  words.append(prompt)\n",
        "  prompts.append([time, prompt])\n",
        "\n",
        "df = pandas.DataFrame(prompts, columns =['en', 'ru'])\n",
        "df.to_excel(os.path.join(data_dir,f'{video_id}.xlsx'), index=None)"
      ],
      "metadata": {
        "id": "6f4u9W2FBVD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get all videos ID from channel"
      ],
      "metadata": {
        "id": "oocvW6hmQuoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channelId = \"UCBobmJyzsJ6Ll7UbfhI4iwQ\"\n",
        "youtube = build('youtube','v3',developerKey= api_key)\n",
        "\n",
        "# getting all video details\n",
        "contentdata = youtube.channels().list(id=channelId,part='contentDetails').execute()\n",
        "playlist_id = contentdata['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "videos = []\n",
        "next_page_token = None\n",
        "\n",
        "while 1:\n",
        "    res = youtube.playlistItems().list(playlistId=playlist_id,part='snippet',maxResults=50,pageToken=next_page_token).execute()\n",
        "    videos += res['items']\n",
        "    next_page_token = res.get('nextPageToken')\n",
        "    if next_page_token is None:\n",
        "        break\n",
        "\n",
        "# getting video id for each video\n",
        "video_ids = list(map(lambda x:x['snippet']['resourceId']['videoId'], videos))\n",
        "# video_ids = video_ids[:4]\n",
        "video_ids"
      ],
      "metadata": {
        "id": "AZ2iIC4OGnmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get subtitles by lines"
      ],
      "metadata": {
        "id": "JJMSbG31uUsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from itertools import zip_longest\n",
        "\n",
        "# list to hold all prompts\n",
        "prompts = []\n",
        "\n",
        "# iterate over each video ID\n",
        "for video_id in video_ids:\n",
        "\n",
        "    try:\n",
        "        subtitles_en = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
        "        subtitles_ru = YouTubeTranscriptApi.get_transcript(video_id, languages=['ru'])\n",
        "    except Exception as e:\n",
        "        print(f\"Exception occurred: {e}\")\n",
        "        continue\n",
        "    list_sub_en = []\n",
        "    list_sub_ru = []\n",
        "    # iterate over each subtitle entry and add to prompts list\n",
        "    for sub_en, sub_ru in zip(subtitles_en, subtitles_ru):\n",
        "        text_en = sub_en['text']\n",
        "        text_ru = sub_ru['text']\n",
        "        list_sub_en.append(text_en)\n",
        "        list_sub_ru.append(text_ru)\n",
        "    max_len = max(len(list_sub_en), len(list_sub_en))\n",
        "    data = list(zip_longest(list_sub_en, list_sub_en, fillvalue=None))\n",
        "    df = pd.DataFrame(data, columns=['en', 'ru'])\n",
        "    sufix = \"\"\n",
        "    if len(list_sub_en) != len(list_sub_ru): sufix = f\"!error_{len(list_sub_en)}-{len(list_sub_ru)}_\"\n",
        "    with pd.ExcelWriter(os.path.join(data_dir, f'{sufix}lines_{channelId}_{video_id}.xlsx')) as writer:\n",
        "        df.to_excel(writer, index=False)\n",
        "    \n",
        "#sentences = combined_sub.split('\\n')\n",
        "#combined_subtitles.extend(sentences)\n",
        "\n",
        "\n",
        "# create dataframe from prompts list\n",
        "#df = pd.DataFrame(prompts, columns=['en', 'ru'])\n",
        "\n",
        "# save dataframe to Excel file\n",
        "#with pd.ExcelWriter(os.path.join(data_dir, f'{channelId}.xlsx')) as writer:\n",
        "#    df.to_excel(writer, index=False)"
      ],
      "metadata": {
        "id": "pAD_vIbHK6IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get subtitles by sentences"
      ],
      "metadata": {
        "id": "AKRGrFbzuZO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from itertools import zip_longest\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def extract_numbers(s):\n",
        "    pattern = r'\\[(\\d+\\.\\d+)\\]'\n",
        "    numbers = re.findall(pattern, s)\n",
        "    cleaned_s = re.sub(pattern, '', s)\n",
        "    return numbers, cleaned_s\n",
        "\n",
        "def compareLists(list1, list2):\n",
        "  i = 0\n",
        "  while i < min(len(list1), len(list2)):\n",
        "    numbers1_1, cleaned_s1_1 = extract_numbers(list1[i])\n",
        "    numbers2_1, cleaned_s2_1 = extract_numbers(list2[i])\n",
        "    if numbers1_1 == numbers2_1:\n",
        "        list1[i] = cleaned_s1_1\n",
        "        list2[i] = cleaned_s2_1\n",
        "        i += 1\n",
        "        continue\n",
        "        \n",
        "    del list1[i]\n",
        "    del list2[i]\n",
        "    if i < min(len(list1), len(list2)) :\n",
        "        numbers1_1, cleaned_s1_1 = extract_numbers(list1[i])\n",
        "        numbers2_1, cleaned_s2_1 = extract_numbers(list2[i])\n",
        "        try:\n",
        "          numbers1_2, cleaned_s1_2 = extract_numbers(list1[i+1])\n",
        "        except:\n",
        "          numbers1_2 = \"\"\n",
        "        try:\n",
        "          numbers2_2, cleaned_s2_2 = extract_numbers(list2[i+1])\n",
        "        except:\n",
        "          numbers2_2 = \"\"\n",
        "        if numbers1_1 == numbers2_2:\n",
        "            del list2[i]\n",
        "        elif numbers2_1 == numbers1_2:\n",
        "            del list1[i]\n",
        "  return list1, list2\n",
        "\n",
        "# list to hold all prompts\n",
        "prompts = []\n",
        "\n",
        "# iterate over each video ID\n",
        "for video_id in video_ids:\n",
        "    print(video_id)\n",
        "\n",
        "    try:\n",
        "        subtitles_en = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n",
        "        subtitles_ru = YouTubeTranscriptApi.get_transcript(video_id, languages=['ru'])\n",
        "    except:\n",
        "        # skip video if it doesn't have English or Russian subtitles\n",
        "        continue\n",
        "    combined_sub_en = \"\"\n",
        "    combined_sub_ru = \"\"\n",
        "    # iterate over each subtitle entry and add to prompts list\n",
        "    for sub_en, sub_ru in zip(subtitles_en, subtitles_ru):\n",
        "        text_en = sub_en['text']\n",
        "        time_en = sub_en['start']\n",
        "\n",
        "        text_ru = sub_ru['text']\n",
        "        time_ru = sub_ru['start']\n",
        "\n",
        "        text_en = re.split(r'(?<=[!?.])+(?=[A-ZА-Я])', text_en)\n",
        "        text_en = \" \".join(text_en)\n",
        "        text_ru = re.split(r'(?<=[!?.])+(?=[A-ZА-Я])', text_ru)\n",
        "        text_ru = \" \".join(text_ru)\n",
        "        text_en = re.sub(r'\\{\\an\\d+\\}\\s*', '', text_en)\n",
        "        text_ru = re.sub(r'\\{\\an\\d+\\}\\s*', '', text_ru)\n",
        "\n",
        "        combined_sub_en += (text_en.replace('\\xa0', ' ').replace('\\n', ' ').replace('...', ',').replace('…', ',').replace('\"', '').replace('\\'', '') + ' ').replace('  ', ' ').replace('  ', ' ') + f\"[{time_en}]\"\n",
        "        combined_sub_ru += (text_ru.replace('\\xa0', ' ').replace('\\n', ' ').replace('...', ',').replace('…', ',').replace('«', '').replace('»', '').replace('\"', '') + ' ').replace('  ', ' ').replace('  ', ' ') + f\"[{time_ru}]\"\n",
        "\n",
        "#        sentences_sub_en = re.split(r'(?<![!?\\.])[!?.]\\s', combined_sub_en)\n",
        "#        sentences_sub_ru = re.split(r'(?<![!?\\.])[!?.]\\s', combined_sub_ru)\n",
        "\n",
        "    sentences_sub_en = re.split(r'(?<=[!?.])\\s', combined_sub_en)\n",
        "    sentences_sub_ru = re.split(r'(?<=[!?.])\\s', combined_sub_ru)\n",
        "    \n",
        "    sentences_sub_en, sentences_sub_ru = compareLists(sentences_sub_en, sentences_sub_ru)\n",
        "\n",
        "\n",
        "    sentences_sub_en = [elem for elem in sentences_sub_en if elem]\n",
        "    sentences_sub_ru = [elem for elem in sentences_sub_ru if elem]\n",
        "\n",
        "    print(video_id)\n",
        "    print(len(sentences_sub_en))\n",
        "    print(len(sentences_sub_ru))\n",
        "    print(\"------------------\")\n",
        "\n",
        "    max_len = max(len(sentences_sub_en), len(sentences_sub_ru))\n",
        "    data = list(zip_longest(sentences_sub_en, sentences_sub_ru, fillvalue=None))\n",
        "    df = pd.DataFrame(data, columns=['en', 'ru'])\n",
        "    sufix = \"\"\n",
        "    if len(sentences_sub_en) != len(sentences_sub_ru): sufix = f\"!error_{len(sentences_sub_en)}-{len(sentences_sub_ru)}_\"\n",
        "    with pd.ExcelWriter(os.path.join(data_dir, f'{sufix}snt_{channelId}_{video_id}.xlsx')) as writer:\n",
        "        df.to_excel(writer, index=False)\n",
        "    \n",
        "#sentences = combined_sub.split('\\n')\n",
        "#combined_subtitles.extend(sentences)\n",
        "\n",
        "\n",
        "# create dataframe from prompts list\n",
        "#df = pd.DataFrame(prompts, columns=['en', 'ru'])\n",
        "\n",
        "# save dataframe to Excel file\n",
        "#with pd.ExcelWriter(os.path.join(data_dir, f'{channelId}.xlsx')) as writer:\n",
        "#    df.to_excel(writer, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p76M8MJPnkg",
        "outputId": "ccd2d649-ba5d-48c9-a128-93109c8eb4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NC8wLmW-owY\n",
            "wanToB8YF_c\n",
            "tLhcS1pAROg\n",
            "dwcaELjcwdA\n",
            "LfAV-OI4ygo\n",
            "3PBnqC7TxvM\n",
            "NMalVTkoy2c\n",
            "BrRA5qdh3RQ\n",
            "C98Dyx8h-H0\n",
            "kT4iWCxu5hA\n",
            "eI1blbMi_KM\n",
            "bLQM6VigTZg\n",
            "4XSrzzQe9gM\n",
            "QFJnKSfd1eM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Further test cells, they are not needed"
      ],
      "metadata": {
        "id": "ROAw3Jvfb9ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['apple', 'banana [1.1]', 'cherry[2.1]',  'banana1', 'banana2',       'apple1[1.23]',  'banana1[12.2]', 'banana5[1.22]']\n",
        "list2 = ['apple', 'banana [1.1]', 'cherry[2.2]',             'banana3',       'apple2[1.23]',  'banana2[12.3]', 'banana2', 'banana6[1.22]']\n",
        "\n",
        "def compareLists(list1, list2):\n",
        "  i = 0\n",
        "  while i < min(len(list1), len(list2)):\n",
        "    numbers1_1, cleaned_s1_1 = extract_numbers(list1[i])\n",
        "    numbers2_1, cleaned_s2_1 = extract_numbers(list2[i])\n",
        "    print(i)\n",
        "    if numbers1_1 == numbers2_1:\n",
        "        print(f\"{list1[i] = } {list2[i] = }\")\n",
        "        list1[i] = cleaned_s1_1\n",
        "        list2[i] = cleaned_s2_1\n",
        "        i += 1\n",
        "        continue\n",
        "        \n",
        "    del list1[i]\n",
        "    del list2[i]\n",
        "    if i < min(len(list1), len(list2)) :\n",
        "        numbers1_1, cleaned_s1_1 = extract_numbers(list1[i])\n",
        "        numbers2_1, cleaned_s2_1 = extract_numbers(list2[i])\n",
        "        try:\n",
        "          numbers1_2, cleaned_s1_2 = extract_numbers(list1[i+1])\n",
        "        except:\n",
        "          numbers1_2 = \"\"\n",
        "        try:\n",
        "          numbers2_2, cleaned_s2_2 = extract_numbers(list2[i+1])\n",
        "        except:\n",
        "          numbers2_2 = \"\"\n",
        "        if numbers1_1 == numbers2_2:\n",
        "            del list2[i]\n",
        "        elif numbers2_1 == numbers1_2:\n",
        "            del list1[i]\n",
        "  return list1, list2\n",
        "        \n",
        "list1, list2 = compareLists(list1, list2)\n",
        "\n",
        "print(list1)\n",
        "print(list2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXOnwHyYFhiQ",
        "outputId": "a6d1e74f-a286-412a-8f73-5f4605247fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "list1[i] = 'apple' list2[i] = 'apple'\n",
            "1\n",
            "list1[i] = 'banana [1.1]' list2[i] = 'banana [1.1]'\n",
            "2\n",
            "2\n",
            "list1[i] = 'banana2' list2[i] = 'banana3'\n",
            "3\n",
            "list1[i] = 'apple1[1.23]' list2[i] = 'apple2[1.23]'\n",
            "4\n",
            "4\n",
            "list1[i] = 'banana5[1.22]' list2[i] = 'banana6[1.22]'\n",
            "['apple', 'banana ', 'banana2', 'apple1', 'banana5']\n",
            "['apple', 'banana ', 'banana3', 'apple2', 'banana6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_numbers(s):\n",
        "    pattern = r'\\[(\\d+\\.\\d+)\\]'\n",
        "    numbers = re.findall(pattern, s)\n",
        "    cleaned_s = re.sub(pattern, '', s)\n",
        "    return numbers, cleaned_s\n",
        "\n",
        "s = 'Альфа — это изображения в оттенках серого с информацией о глубине, [83.41]которые мы можем присвоить кистям для скульптинга, чтобы быстро вылепить детали и ускорить весь [87.34]процесс скульптинга.'\n",
        "numbers, cleaned_s = extract_numbers(s)\n",
        "print(numbers)  # output: ['1080.24', '234.4']\n",
        "print(cleaned_s)  # output: 'И с помощью кисти Nudge я немного сформировал поток волос или меха, так как мне нравится.'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YICHgkJQ37HM",
        "outputId": "252dbc4f-92bc-433a-f412-7fd9cb4d5b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['83.41', '87.34']\n",
            "Альфа — это изображения в оттенках серого с информацией о глубине, которые мы можем присвоить кистям для скульптинга, чтобы быстро вылепить детали и ускорить весь процесс скульптинга.\n"
          ]
        }
      ]
    }
  ]
}